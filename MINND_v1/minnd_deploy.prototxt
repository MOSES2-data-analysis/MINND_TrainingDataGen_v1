name: "MINND_v1"
# Data layer for storing input images
# These images are the results of the MOSES forward model
input: "input"
input_shape {
	dim: 1
	dim: 3
	dim: 8
	dim: 8
}

# First Convolutional Layer
layer {
	name: 	"conv1"
	type: 	"Convolution"
	bottom: "input"
	top: 	"conv1"
	
	# learning rate and decay multipliers for the filters
	param { lr_mult: 1 decay_mult: 1 }
	# learning rate and decay multipliers for the biases
	param { lr_mult: 2 decay_mult: 0 }
  
	convolution_param {
		num_output:		32
		kernel_size:	5
		stride:			1
    }
}

# Max pooling layer
layer {
	name: "pool1"
	type: "Pooling"
	bottom: "conv1"
	top: "pool1"
	pooling_param {
		pool: MAX
		kernel_size: 2
		stride: 1
	}
}

# Second Convolutional Layer
layer {
	name: 	"conv2"
	type: 	"Convolution"
	bottom: "pool1"
	top: 	"conv2"
	
	# learning rate and decay multipliers for the filters
	param { lr_mult: 1 decay_mult: 1 }
  	# learning rate and decay multipliers for the biases
  	param { lr_mult: 2 decay_mult: 0 }
  
	convolution_param {	
	  	num_output:		128
	  	kernel_size:	2
	  	stride:			1
    }
}

# Max pooling layer
layer {
	name: "pool2"
	type: "Pooling"
	bottom: "conv2"
	top: "pool2"
	pooling_param {
		pool: MAX
		kernel_size: 2
		stride: 1
	}
}

# First fully-connected layer
layer {
	name: "ip1"
	type: "InnerProduct"
	bottom: "pool2"
	top: "ip1"
	
	# learning rate and decay multipliers for the filters
	param { lr_mult: 1 decay_mult: 1 }
  	# learning rate and decay multipliers for the biases
  	param { lr_mult: 2 decay_mult: 0 }
  	
	inner_product_param {
		num_output: 192
    }
}

# Rectified Linear Unit layer
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}

# Second fully-connected layer
layer {
	name: "ip2"
	type: "InnerProduct"
	bottom: "ip1"
	top: "ip2"
	
	# learning rate and decay multipliers for the filters
	param { lr_mult: 1 decay_mult: 1 }
  	# learning rate and decay multipliers for the biases
  	param { lr_mult: 2 decay_mult: 0 }
  	
	inner_product_param {
		num_output: 256	
    }
}



# Rectified Linear Unit layer
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}

# Third fully-connected layer
layer {
	name: "ip3"
	type: "InnerProduct"
	bottom: "ip2"
	top: "ip3"
	
	# learning rate and decay multipliers for the filters
	param { lr_mult: 1 decay_mult: 1 }
  	# learning rate and decay multipliers for the biases
  	param { lr_mult: 2 decay_mult: 0 }
  	
	inner_product_param {
		num_output: 64	
    }
}

# Reshape to be the same dimensions as the truth
layer {
	name: "reshape_ip3"
	type: "Reshape"
	bottom: "ip3"
	top: "reshape_ip3"
	reshape_param {
		shape {
			dim: 0  # copy the dimension from below
			dim: 1	
			dim: 8
			dim: 8
		}
	}
}

















